{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNkgjdMxUlnDstVS3FHK+iZ"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["Here we are focusing on developing a pipeline for text tokenization and noise reduction, specifically for analyzing historical religious and biblical texts. Utilizing a combination of Natural Language Processing (NLP) libraries such as NLTK and SpaCy, the task aims to preprocess and tokenize a dataset of Asian religious and biblical texts obtained from the UCI Machine Learning Repository."],"metadata":{"id":"UnnbgffZ7TQk"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"VYrwMxIQEff2"},"outputs":[],"source":["# Download necessary libraries and packages for tokenization\n","!pip install nltk -U -q\n","!pip install spacy -U -q"]},{"cell_type":"code","source":["# You can also use this section to suppress warnings generated by your code:\n","def warn(*args, **kwargs):\n","    pass\n","import warnings\n","warnings.warn = warn\n","warnings.filterwarnings('ignore')\n","\n","import nltk\n","import re\n","import spacy\n","import zipfile\n","import requests\n","from io import BytesIO\n","from nltk.tokenize import word_tokenize\n","\n","# download and install the spacy language model\n","!python3 -m spacy download en_core_web_sm\n","sp = spacy.load('en_core_web_sm')\n","\n","# download the 'punkt' tokenizer models\n","nltk.download('punkt')\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"iiVOXAcgd2ty","executionInfo":{"status":"ok","timestamp":1718615569473,"user_tz":-330,"elapsed":25227,"user":{"displayName":"Swaraj Gupta","userId":"06929796091355634186"}},"outputId":"3368c25c-f4ff-4204-afeb-4a5fae5e4204"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting en-core-web-sm==3.7.1\n","  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.7.1/en_core_web_sm-3.7.1-py3-none-any.whl (12.8 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.8/12.8 MB\u001b[0m \u001b[31m64.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: spacy<3.8.0,>=3.7.2 in /usr/local/lib/python3.10/dist-packages (from en-core-web-sm==3.7.1) (3.7.5)\n","Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.0.12)\n","Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.0.5)\n","Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.0.10)\n","Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.0.8)\n","Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.0.9)\n","Requirement already satisfied: thinc<8.3.0,>=8.2.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (8.2.4)\n","Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.1.3)\n","Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.4.8)\n","Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.0.10)\n","Requirement already satisfied: weasel<0.5.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.4.1)\n","Requirement already satisfied: typer<1.0.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.12.3)\n","Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (4.66.4)\n","Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.31.0)\n","Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.7.3)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.1.4)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (67.7.2)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (24.1)\n","Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.4.0)\n","Requirement already satisfied: numpy>=1.19.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.25.2)\n","Requirement already satisfied: language-data>=1.2 in /usr/local/lib/python3.10/dist-packages (from langcodes<4.0.0,>=3.2.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.2.0)\n","Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.7.0)\n","Requirement already satisfied: pydantic-core==2.18.4 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.18.4)\n","Requirement already satisfied: typing-extensions>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (4.12.2)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.7)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2024.6.2)\n","Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.7.11)\n","Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.1.5)\n","Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (8.1.7)\n","Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.5.4)\n","Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (13.7.1)\n","Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.18.1)\n","Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (7.0.4)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.1.5)\n","Requirement already satisfied: marisa-trie>=0.7.7 in /usr/local/lib/python3.10/dist-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.2.0)\n","Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.0.0)\n","Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.16.1)\n","Requirement already satisfied: wrapt in /usr/local/lib/python3.10/dist-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.14.1)\n","Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.1.2)\n","\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n","You can now load the package via spacy.load('en_core_web_sm')\n","\u001b[38;5;3m⚠ Restart to reload dependencies\u001b[0m\n","If you are in a Jupyter or Colab notebook, you may need to restart Python in\n","order to load all the package's dependencies. You can do this by selecting the\n","'Restart kernel' or 'Restart runtime' option.\n"]},{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Unzipping tokenizers/punkt.zip.\n"]},{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{},"execution_count":2}]},{"cell_type":"code","source":["url = 'https://archive.ics.uci.edu/static/public/512/a+study+of+asian+religious+and+biblical+texts.zip'\n","\n","# Download and extract the ZIP file\n","response=requests.get(url)\n","\n","with zipfile.ZipFile(BytesIO(response.content)) as z:\n","\n","  # Extract 'complete_data.txt' from the ZIP file\n","  with z.open('Complete_data .txt') as file:\n","\n","    # Read and decode the file\n","    working_txt = file.read().decode('utf-8',errors='ignore')\n","    # Clean text by removing successive whitespace and line breaks\n","    clean_txt=re.sub(r\"\\s+\",\" \",working_txt)\n","\n","print(clean_txt[:50])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5mhZe3GFeA56","executionInfo":{"status":"ok","timestamp":1718616776006,"user_tz":-330,"elapsed":1387,"user":{"displayName":"Swaraj Gupta","userId":"06929796091355634186"}},"outputId":"cb8a369d-a67c-4e1b-d21f-376fc6a7cf6f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["0.1 1.The Buddha: \"What do you think, Rahula: What\n"]}]},{"cell_type":"code","source":["tokens = word_tokenize(clean_txt)\n","print(tokens[:50])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5SPzFpDHgZkD","executionInfo":{"status":"ok","timestamp":1718616826366,"user_tz":-330,"elapsed":1564,"user":{"displayName":"Swaraj Gupta","userId":"06929796091355634186"}},"outputId":"12532890-af19-4a46-ba2a-3e7711d17e73"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["['0.1', '1.The', 'Buddha', ':', '``', 'What', 'do', 'you', 'think', ',', 'Rahula', ':', 'What', 'is', 'a', 'mirror', 'for', '?', '``', 'The', 'Buddha', ':', 'Rahula', ':', '``', 'For', 'reflection', ',', 'sir', '.', '``', 'Rahula', ':', 'The', 'Buddha', ':', '``', 'In', 'the', 'same', 'way', ',', 'Rahula', ',', 'bodily', 'acts', ',', 'verbal', 'acts', ',']\n"]}]},{"cell_type":"markdown","source":["**removing noise**"],"metadata":{"id":"qKbxalhmliSW"}},{"cell_type":"markdown","source":["* Remove successive whitespace and line breaks to standardize the text format.\n","* Replace non-alphabetic characters with single whitespace to focus on alphabetic content.\n","* Eliminate any leading and trailing whitespace to ensure clean token boundaries.\n"],"metadata":{"id":"Af4EcRmK7dKz"}},{"cell_type":"code","source":["# replace non-alphabetic characters with single whitespace\n","reg_txt=re.sub(r'[^a-zA-Z\\s]',' ',clean_txt)\n","print(reg_txt[:50])\n","\n","#remove any whitespace that appears in sequence\n","reg_txt=re.sub(r'\\s+',' ',reg_txt)\n","print(reg_txt[:50])\n","\n","# remove any new leading and trailing whitespace\n","reg_txt=reg_txt.strip()\n","print(reg_txt[:50])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mcnTuh5Ei24S","executionInfo":{"status":"ok","timestamp":1718617398616,"user_tz":-330,"elapsed":629,"user":{"displayName":"Swaraj Gupta","userId":"06929796091355634186"}},"outputId":"667364f8-5854-42c2-ab83-f4ebbb2e587f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["      The Buddha   What do you think  Rahula  What\n"," The Buddha What do you think Rahula What is a mir\n","The Buddha What do you think Rahula What is a mirr\n"]}]},{"cell_type":"markdown","source":["**Word Tokenization:** Split the cleaned text into individual words using NLTK's word_tokenize method."],"metadata":{"id":"gnquU8pQ7q4r"}},{"cell_type":"code","source":["#tokenize regularized text\n","reg_tokens=word_tokenize(reg_txt)\n","print(reg_tokens[:50])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"SDS1-farksha","executionInfo":{"status":"ok","timestamp":1718617460201,"user_tz":-330,"elapsed":410,"user":{"displayName":"Swaraj Gupta","userId":"06929796091355634186"}},"outputId":"ba0c83a6-8e8d-46ac-cea2-386ccbaf06ea"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["['The', 'Buddha', 'What', 'do', 'you', 'think', 'Rahula', 'What', 'is', 'a', 'mirror', 'for', 'The', 'Buddha', 'Rahula', 'For', 'reflection', 'sir', 'Rahula', 'The', 'Buddha', 'In', 'the', 'same', 'way', 'Rahula', 'bodily', 'acts', 'verbal', 'acts', 'mental', 'acts', 'are', 'to', 'be', 'done', 'with', 'repeated', 'reflection', 'The', 'Buddha', 'Whenever', 'you', 'want', 'to', 'perform', 'a', 'bodily', 'act', 'you']\n"]}]},{"cell_type":"markdown","source":["**Character Tokenization:** Tokenize the text at the character level using regular expressions."],"metadata":{"id":"TPtMxYVw7317"}},{"cell_type":"code","source":["from nltk.tokenize import regexp_tokenize"],"metadata":{"id":"VipHixxXlUmz"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(clean_txt[:50])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ptXGBzfLouF5","executionInfo":{"status":"ok","timestamp":1718618360335,"user_tz":-330,"elapsed":471,"user":{"displayName":"Swaraj Gupta","userId":"06929796091355634186"}},"outputId":"0e37eba2-17a6-4a1a-959e-4100d60d8551"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["0.1 1.The Buddha: \"What do you think, Rahula: What\n"]}]},{"cell_type":"code","source":["pattern=r\"\\S|\\s\"\n","character_tokens=regexp_tokenize(clean_txt,pattern)\n","print(character_tokens[:50])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Rdep12WUmpGI","executionInfo":{"status":"ok","timestamp":1718617962222,"user_tz":-330,"elapsed":6,"user":{"displayName":"Swaraj Gupta","userId":"06929796091355634186"}},"outputId":"cc31f1f3-2c50-4e3e-e648-39cb3f657e95"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["['0', '.', '1', ' ', '1', '.', 'T', 'h', 'e', ' ', 'B', 'u', 'd', 'd', 'h', 'a', ':', ' ', '\"', 'W', 'h', 'a', 't', ' ', 'd', 'o', ' ', 'y', 'o', 'u', ' ', 't', 'h', 'i', 'n', 'k', ',', ' ', 'R', 'a', 'h', 'u', 'l', 'a', ':', ' ', 'W', 'h', 'a', 't']\n"]}]},{"cell_type":"markdown","source":["**Sentence Tokenization:** Divide the text into sentences using NLTK's sent_tokenize method."],"metadata":{"id":"liY0NXGroiv4"}},{"cell_type":"code","source":["from nltk.tokenize import sent_tokenize"],"metadata":{"id":"znlvDWQBnPC3"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(clean_txt[:50])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"B931g4tXo4qw","executionInfo":{"status":"ok","timestamp":1718618405085,"user_tz":-330,"elapsed":439,"user":{"displayName":"Swaraj Gupta","userId":"06929796091355634186"}},"outputId":"9961a3da-b084-432a-f477-7a4d44ccc0cf"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["0.1 1.The Buddha: \"What do you think, Rahula: What\n"]}]},{"cell_type":"code","source":["sentence_tokens=sent_tokenize(clean_txt)\n","print(sentence_tokens[:5])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8ldAVdtPo7SC","executionInfo":{"status":"ok","timestamp":1718618456873,"user_tz":-330,"elapsed":461,"user":{"displayName":"Swaraj Gupta","userId":"06929796091355634186"}},"outputId":"284c50c7-d6a3-4a88-ebd0-c0f430efd878"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["['0.1 1.The Buddha: \"What do you think, Rahula: What is a mirror for?', '\"The Buddha:Rahula: \"For reflection, sir.', '\"Rahula:The Buddha: \"In the same way, Rahula, bodily acts, verbal acts, & mental acts are to be done with repeated reflection.The Buddha:\"Whenever you want to perform a bodily act, you should reflect on it: \\'This bodily act I want to perform would it lead to self-affliction, to the affliction of others, or to both?', \"Is it an unskillful bodily act, with painful consequences, painful results?'\", 'If, on reflection, you know that it would lead to self-affliction, to the affliction of others, or to both; it would be an unskillful bodily act with painful consequences, painful results, then any bodily act of that sort is absolutely unfit for you to do.']\n"]}]}]}